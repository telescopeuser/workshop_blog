{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.iss.nus.edu.sg/Sitefinity/WebsiteTemplates/ISS/App_Themes/ISS/Images/branding-iss.png' width=15% style=\"float: right;\">\n",
    "<img src='https://www.iss.nus.edu.sg/Sitefinity/WebsiteTemplates/ISS/App_Themes/ISS/Images/branding-nus.png' width=15% style=\"float: right;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython.display\n",
    "# IPython.display.YouTubeVideo('TBD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何使用和开发微信聊天机器人的系列教程\n",
    "# A workshop to develop & use an intelligent and interactive chat-bot in WeChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WeChat is a popular social media app, which has more than 800 million monthly active users.\n",
    "\n",
    "<img src='https://www.iss.nus.edu.sg/images/default-source/About-Us/7.6.1-teaching-staff/sam-website.tmb-.png' width=8% style=\"float: right;\">\n",
    "<img src='../reference/WeChat_SamGu_QR.png' width=10% style=\"float: right;\">\n",
    "\n",
    "\n",
    "by: GU Zhan (Sam)\n",
    "\n",
    "\n",
    "October 2018 : Update to support Python 3 in local machine, e.g. iss-vm.\n",
    "\n",
    "\n",
    "April 2017 ======= Scan the QR code to become trainer's friend in WeChat =====>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第六课：交互式虚拟助手的智能应用\n",
    "### Lesson 6: Interactive Conversatioinal Virtual Assistant Applications / Intelligent Process Automations\n",
    "* 虚拟员工: 贷款填表申请审批一条龙自动化流程 （Virtual Worker: When Chat-bot meets RPA-bot for mortgage loan application automation) \n",
    "* 虚拟员工: 文字指令交互（Conversational automation using text/message command) \n",
    "* 虚拟员工: 语音指令交互（Conversational automation using speech/voice command) \n",
    "* 虚拟员工: 多种语言交互（Conversational automation with multiple languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Google Cloud Platform's Machine Learning APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "**<li> Google Cloud Speech API </li>**\n",
    "**<li> Google Cloud Text-to-Speech API </li>**\n",
    "**<li> Google Cloud Translation API </li>**\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "# !pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Virtual Worker: When Chat-bot meets RPA-bot</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 虚拟员工: 贷款填表申请审批一条龙自动化流程 （Mortgage loan application automation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous processing when triggering RPA-Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library/Function to use operating system's shell script command, e.g. bash, echo, cd, pwd, etc\n",
    "import subprocess, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton to trigger RPA-Bot (TagUI script: mortgage loan application automation) from VA-Bot (python script)\n",
    "# Trigger RPA-Bot [ Synchronous  ]\n",
    "# def didi_invoke_rpa_bot(rpa_bot_file, rpa_bot = 'reference/S-IPA-Workshop/TagUI-S-IPA/src/tagui'):\n",
    "def didi_invoke_rpa_bot(rpa_bot_file, rpa_bot = '../reference/S-IPA-Workshop/TagUI-S-IPA/src/tagui'):\n",
    "\n",
    "# Invoke RPA-Bot script\n",
    "    print('[ W I P ] In progress to invoke RPA-Bot using command: \\n{}'.format(\n",
    "            'bash' + ' ' + rpa_bot + ' ' + rpa_bot_file))\n",
    "    start = time.time()\n",
    "    return_code = subprocess.call(['bash', rpa_bot, rpa_bot_file])\n",
    "    end = time.time()\n",
    "    if return_code == 0:\n",
    "        print('[  Sync OK  ] RPA-Bot succeeded! [ Return Code : {} ]'.format(return_code))\n",
    "    else:\n",
    "        print('[ ERROR ] RPA-Bot failed! [ Return Code : {} ]'.format(return_code))\n",
    "\n",
    "    return return_code, int(round(end - start, 0)) # return_code & time_spent in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# rpa_bot_file = 'reference/S-IPA-Workshop/workshop3/VisualAutomation/KIE-Loan-Applicaiton-VA-Serverless/VA-KIE-Loan-Applicaiton.txt'\n",
    "# return_code = didi_invoke_rpa_bot(rpa_bot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous processing when triggering RPA-Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger RPA-Bot [ Asynchronous  ]\n",
    "# http://docs.dask.org/en/latest/_downloads/daskcheatsheet.pdf\n",
    "from dask.distributed import Client\n",
    "def didi_invoke_rpa_bot_async(rpa_bot_file):\n",
    "    client = Client(processes=False)\n",
    "    ipa_task = client.submit(didi_invoke_rpa_bot, rpa_bot_file)\n",
    "    ipa_task.add_done_callback(didi_invoke_rpa_bot_async_upon_completion)\n",
    "    return 0, 0 # Dummy return. Actual result is returned by function didi_invoke_rpa_bot_async_upon_completion(ipa_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tornado import gen \n",
    "# https://stackoverflow.com/questions/40477518/how-to-get-the-result-of-a-future-in-a-callback\n",
    "@gen.coroutine\n",
    "def didi_invoke_rpa_bot_async_upon_completion(ipa_task):\n",
    "    print(u'[ Terminal Info ] didi_invoke_rpa_bot_async(rpa_bot_file) [ upon_completion ]')\n",
    "    return_code, time_spent = ipa_task.result()\n",
    "    print(return_code)\n",
    "    print(time_spent)\n",
    "    \n",
    "    # Send confirmation message upon triggering RPA-Bot \n",
    "#     itchat.send(u'[ Async OK ] IPA Command completed !\\n[ Time Spent : %s seconds ]\\n %s' % (time_spent, parm_msg['Text']), parm_msg['FromUserName'])\n",
    "    itchat.send(u'[ Async OK ] IPA Command completed !\\n[ Time Spent : %s seconds ]' % (time_spent), parm_msg['FromUserName']) # parm_msg['Text'] can be in-sync due to new coming message.\n",
    "#     return return_code, time_spent # No return needed. No pace to hold the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# rpa_bot_file = 'reference/S-IPA-Workshop/workshop3/VisualAutomation/KIE-Loan-Applicaiton-VA-Serverless/VA-KIE-Loan-Applicaiton.txt'\n",
    "# return_code = didi_invoke_rpa_bot_async(rpa_bot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[ Start of IPA-Bot ] Continue other tasks in main program...\\n...\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Wrap RPA-Bot into Functions() for conversational virtual assistant (VA):</span>\n",
    "Reuse above defined Functions()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 虚拟员工: 文字指令交互（Conversational automation using text/message command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm_msg = {} # Define a global variable to hold current msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \"keywords intention command -> automation action\" lookup to invoke RPA-Bot process automation functions\n",
    "parm_bot_intention_action = {\n",
    "      '#apply_loan': '../reference/S-IPA-Workshop/workshop3/VisualAutomation/KIE-Loan-Applicaiton-VA-Serverless/VA-KIE-Loan-Applicaiton.txt'\n",
    "    , '#ocr_invoice': '../reference/S-IPA-Workshop/workshop3/VisualAutomation/KIE-Loan-Applicaiton-VA-Serverless/VA-KIE-Loan-Applicaiton.txt'\n",
    "    , '#check_applicaiton': '../reference/S-IPA-Workshop/workshop3/VisualAutomation/KIE-Loan-Applicaiton-VA-Serverless/VA-KIE-Loan-Applicaiton.txt'\n",
    "    , '#hi_everyone_welcome_to_see_you_here_in_the_process_automation_course': '../reference/S-IPA-Workshop/workshop3/VisualAutomation/KIE-Loan-Applicaiton-VA-Serverless/VA-KIE-Loan-Applicaiton.txt'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve rpa_bot_file based on received Chat-Bot command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve rpa_bot_file based on received Chat-Bot command\n",
    "def didi_retrieve_rpa_bot_file(chat_bot_command):\n",
    "    print('[ W I P ] Retrieve rpa_bot_file based on received Chat-Bot command : {} -> {}'.format(\n",
    "        chat_bot_command, chat_bot_command.lower()))\n",
    "    \n",
    "    if chat_bot_command.lower() in parm_bot_intention_action.keys():\n",
    "        return parm_bot_intention_action[chat_bot_command.lower()]\n",
    "    else:\n",
    "        print('[ ERROR ] Command not found!')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# didi_retrieve_rpa_bot_file('#apply_loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# didi_retrieve_rpa_bot_file('#Apply_Loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# didi_retrieve_rpa_bot_file('#approve_loan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 虚拟员工: 语音指令交互（Conversational automation using speech/voice command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Use local AI module in native forms</span> for Speech Recognition: Speech-to-Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要用到的一些功能程序库： Local AI Module Speech-to-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local AI Module for Speech Synthesis: Speech-to-Text\n",
    "\n",
    "# Install library into computer storage:\n",
    "# !pip install SpeechRecognition\n",
    "\n",
    "# !pip install pocketsphinx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library into computer memory:\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF **!pip install pocketsphinx** failed, THEN: **sudo apt-get install python python-dev python-pip build-essential swig libpulse-dev**\n",
    "\n",
    "https://stackoverflow.com/questions/36523705/python-pocketsphinx-requesterror-missing-pocketsphinx-module-ensure-that-pocke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Languages  \n",
    "\n",
    "https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst#installing-other-languages.\n",
    "\n",
    "By default, SpeechRecognition's Sphinx functionality supports only US English. Additional language packs are also available:\n",
    "* English (Default support) : **en-US**\n",
    "* International French : **fr-FR**\n",
    "* Mandarin Chinese : **zh-CN**\n",
    "* Italian : **it-IT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function to convert mp3 file to 'wav / flac' audio file type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to indicate the environment to run this program:\n",
    "\n",
    "# Uncomment to run the code on Google Cloud Platform\n",
    "# parm_runtime_env_GCP = True\n",
    "\n",
    "# Uncomment to run the code in local machine\n",
    "parm_runtime_env_GCP = False\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Utility function to convert mp3 file to target GCP audio file type:\n",
    "#    audio_type = ['flac', 'wav']\n",
    "#    audio_file_input = msg['FileName']\n",
    "\n",
    "# Running Speech API\n",
    "def didi_mp3_audio_conversion(audio_file_input, audio_type='flac'):\n",
    "    audio_file_output = str(audio_file_input) + '.' + str(audio_type)\n",
    "    \n",
    "    # convert mp3 file to target GCP audio file:\n",
    "\n",
    "# remove audio_file_output, if exists\n",
    "    retcode = subprocess.call(['rm', audio_file_output])\n",
    "    \n",
    "    if parm_runtime_env_GCP: # using Datalab in Google Cloud Platform\n",
    "        # GCP: use avconv to convert audio\n",
    "        retcode = subprocess.call(['avconv', '-i', audio_file_input, '-ac', '1', audio_file_output])\n",
    "    else: # using an iss-vm Virtual Machine, or local machine\n",
    "        # VM : use ffmpeg to convert audio\n",
    "        retcode = subprocess.call(['ffmpeg', '-i', audio_file_input, '-ac', '1', audio_file_output])\n",
    "    \n",
    "    if retcode == 0:\n",
    "        print('[  O K  ] Converted  audio file for API: %s' % audio_file_output)\n",
    "    else:\n",
    "        print('[ ERROR ] Function: didi_mp3_audio_conversion() Return Code is : {}'.format(retcode))\n",
    "\n",
    "    return audio_file_output # return file name string only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion for files not in wav or flac format:\n",
    "# AUDIO_FILE = didi_mp3_audio_conversion(\"reference/S-IPA-welcome.mp3\")\n",
    "# AUDIO_FILE = didi_mp3_audio_conversion(\"reference/S-IPA-welcome.mp3\", 'wav')\n",
    "# AUDIO_FILE = didi_mp3_audio_conversion(\"reference/text2speech.mp3\")\n",
    "# AUDIO_FILE = didi_mp3_audio_conversion(\"reference/text2speech.mp3\", 'wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Local AI Module: speech_recognition.Recognizer().recognize_sphinx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Local AI Module Speech-to-Text\n",
    "def didi_speech2text_local(AUDIO_FILE, didi_language_code='en-US'):\n",
    "    # Python 2\n",
    "\n",
    "    # use the audio file as the audio source\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file\n",
    "        \n",
    "    transcription = ''\n",
    "    # recognize speech using Sphinx\n",
    "    try:\n",
    "        transcription = r.recognize_sphinx(audio, language=didi_language_code)\n",
    "        print(\"[ Terminal Info ] Sphinx thinks you said : \\'{}\\'.\".format(transcription))\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"[ Terminal Info ] Sphinx could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"[ Terminal Info ] Sphinx error; {0}\".format(e))\n",
    "    \n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# transcription = didi_speech2text_local(didi_mp3_audio_conversion(\"reference/S-IPA-welcome.mp3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# transcription = didi_speech2text_local(\"reference/S-IPA-welcome.mp3.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy match from 'transcribed audio command' to predefined 'chat_bot_command'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically create a new lookup, by converting text-based intention command to voice-based intention command.\n",
    "\n",
    "Example: from '#apply_loan' to 'voice command apply loan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json # Prints the nicely formatted dictionary\n",
    "# print(json.dumps(parm_bot_intention_action, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "parm_bot_intention_action_fuzzy_match = {}\n",
    "for intention, action in parm_bot_intention_action.items():\n",
    "#     print(intention)\n",
    "    intention_fuzzy_match = \" \".join(re.split('#|_', intention.replace('#', 'voice_command_')))\n",
    "#     print(action)\n",
    "    parm_bot_intention_action_fuzzy_match[intention_fuzzy_match] = action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(parm_bot_intention_action_fuzzy_match, indent=4, sort_keys=True))\n",
    "# print(parm_bot_intention_action_fuzzy_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy match function: Compare similarity between two text strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare similarity between two text strings\n",
    "def did_fuzzy_match_score(string1, string2):\n",
    "    print('\\n[ Inside FUNCTION ] did_fuzzy_match_score')\n",
    "    string1_list = string1.lower().split() # split by space\n",
    "    string2_list = string2.lower().split() # split by space   \n",
    "\n",
    "    print('string1_list : ', string1_list)\n",
    "    print('string2_list : ', string2_list)\n",
    "    \n",
    "    # words in common\n",
    "    common_words = set(string1_list)&set(string2_list)\n",
    "#     print('len(common_words)  : ', len(common_words))\n",
    "\n",
    "    # totoal unique words\n",
    "    unique_words = set(string1_list + string2_list)\n",
    "#     print('len(unique_words)  : ', len(unique_words))\n",
    "    \n",
    "    jaccard_similarity = float(len(common_words) / len(unique_words))\n",
    "\n",
    "    print('jaccard_similarity : {0:.3f}'.format(jaccard_similarity))\n",
    "    \n",
    "    return jaccard_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# did_fuzzy_match_score('run DIDI voice command apply loan', 'voice command apply loan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve rpa_bot_file based on received Chat-Bot command ( fuzzy match for voice/speech2text )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve rpa_bot_file based on received Chat-Bot command ( fuzzy match for voice/speech2text )\n",
    "def didi_retrieve_rpa_bot_file_fuzzy_match(speech2text_chat_bot_command, didi_confidence_threshold=0.8):\n",
    "    print('\\n[ Inside FUNCTION ] didi_retrieve_rpa_bot_file_fuzzy_match')\n",
    "    matched_intention = [0.0, {}] # a lis to store intention_command of highest jaccard_similarity\n",
    "\n",
    "    for intention, action in parm_bot_intention_action_fuzzy_match.items():\n",
    "#         print('\\nintention : ', intention)\n",
    "#         print('action : ', action)\n",
    "        fuzzy_match_score_current = did_fuzzy_match_score(intention, speech2text_chat_bot_command)\n",
    "#         print('jaccard_similarity_score_current : ', jaccard_similarity_score_current)\n",
    "        if fuzzy_match_score_current > matched_intention[0]:\n",
    "            matched_intention[0] = fuzzy_match_score_current\n",
    "            matched_intention[1] = {intention : action}\n",
    "#             print('matched_intention : ', matched_intention)\n",
    "    \n",
    "    print('\\n[ Finale ] matched_intention : ', matched_intention)\n",
    "    \n",
    "    if matched_intention[0] < didi_confidence_threshold: # not confident enough about fuzzy matched voice command\n",
    "        return None\n",
    "    else: # confident enough, thus return predefined rpa_bot_file\n",
    "        return str(list(matched_intention[1].values())[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment below lines for an agile demo outside Chat-bot:\n",
    "# parm_voice_command_confidence_threshold = 0.6 # Control of asynchronous or synchronous processing when triggering RPA-Bot\n",
    "# action_rpa_bot_file = didi_retrieve_rpa_bot_file_fuzzy_match('run DIDI voice command apply loan', parm_voice_command_confidence_threshold)\n",
    "# print('\\n[ Process Automation ] rpa_bot_file : ', action_rpa_bot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Parm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control of asynchronous or synchronous processing when triggering RPA-Bot\n",
    "parm_asynchronous_process = True\n",
    "\n",
    "# Control of asynchronous or synchronous processing when triggering RPA-Bot\n",
    "parm_voice_command_confidence_threshold = 0.05 # low value for demo only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Start interactive conversational virtual assistant (VA):</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ItChat, etc. 导入需要用到的一些功能程序库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itchat\n",
    "from itchat.content import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log in using QR code image / 用微信App扫QR码图片来自动登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Running in Jupyther Notebook:\n",
    "# itchat.auto_login(hotReload=True) # hotReload=True: 退出程序后暂存登陆状态。即使程序关闭，一定时间内重新开启也可以不用重新扫码。\n",
    "# or\n",
    "# itchat.auto_login(enableCmdQR=-2) # enableCmdQR=-2: Jupyter Notebook 命令行显示QR图片\n",
    "\n",
    "# Running in Terminal:\n",
    "itchat.auto_login(enableCmdQR=2) # enableCmdQR=2: 命令行显示QR图片 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 虚拟员工: 文字指令交互（Conversational automation using text/message command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger RPA-Bot when command received / 如果收到[TEXT]的信息：\n",
    "@itchat.msg_register([TEXT]) # 文字\n",
    "def didi_ipa_text_command(msg):\n",
    "    global parm_msg\n",
    "    parm_msg = msg\n",
    "    if msg['Text'][0] == '#':\n",
    "        # Retrieve rpa_bot_file based on received Chat-Bot command\n",
    "        rpa_bot_file = didi_retrieve_rpa_bot_file( msg['Text'])\n",
    "        \n",
    "        if rpa_bot_file == None: # input command / rpa_bot_file NOT FOUND!\n",
    "            print(u'[ Terminal Info ] RPA-Bot [ ERROR ] Command not found : [ %s ] %s From: %s' \n",
    "                  % (msg['Type'], msg['Text'], msg['FromUserName']))\n",
    "            itchat.send(u'RPA-Bot [ ERROR ] Command not found : \\n[ %s ]\\n%s' % (msg['Type'], msg['Text']), msg['FromUserName'])\n",
    "        else:\n",
    "            print(u'[ Terminal Info ] RPA-Bot [ W I P ] Command : [ %s ] %s From: %s' \n",
    "                  % (msg['Type'], msg['Text'], msg['FromUserName']))\n",
    "            print(u'[ Terminal Info ] RPA-Bot [ W I P ] File    : %s' % (rpa_bot_file))\n",
    "            \n",
    "            if parm_asynchronous_process: # Don't wait for RPA-Bot completion \n",
    "                # Send 'work in progress' message triggering RPA-Bot\n",
    "                itchat.send(u'[ Async WIP ] IPA Command triggered: \\n[ %s ]\\n%s' % (msg['Type'], msg['Text']), msg['FromUserName'])\n",
    "                \n",
    "                # Trigger RPA-Bot [ Asynchronous ]\n",
    "                didi_invoke_rpa_bot_async(rpa_bot_file) # No return of return_code, time_spent\n",
    "            else: # Wait for RPA-Bot completion \n",
    "                # Send 'work in progress' message triggering RPA-Bot\n",
    "                itchat.send(u'[ Sync WIP ] IPA Command triggered: \\n[ %s ]\\n%s' % (msg['Type'], msg['Text']), msg['FromUserName'])\n",
    "                \n",
    "                # Trigger RPA-Bot [ Synchronously ]\n",
    "                return_code, time_spent = didi_invoke_rpa_bot(rpa_bot_file)\n",
    "                print(u'[ Terminal Info ] didi_invoke_rpa_bot(rpa_bot_file) [ Return Code : %s ]' % (return_code))\n",
    "                \n",
    "                if return_code == 0:\n",
    "                    # Send confirmation message upon RPA-Bot completion\n",
    "                    itchat.send(u'[ Sync OK ] IPA Command completed : \\n[ %s ]\\n%s\\n[ Time Spent : %s seconds ]' % (msg['Type'], msg['Text'], time_spent), msg['FromUserName'])\n",
    "                else:\n",
    "                    # Error when running RPA-Bot task\n",
    "                    itchat.send(u'[ Sync ERROR] [ Return Code : %s ] IPA Command failed : \\n[ %s ]\\n%s\\n[ Time Spent : %s seconds ]' % (return_code, msg['Type'], msg['Text'], time_spent), msg['FromUserName'])\n",
    "                    \n",
    "    else:\n",
    "        print(u'[ Terminal Info ] Thank you! 谢谢亲[嘴唇]我已收到 I received: [ %s ] %s From: %s' \n",
    "              % (msg['Type'], msg['Text'], msg['FromUserName']))\n",
    "        itchat.send(u'Thank you! 谢谢亲[嘴唇]我已收到\\nI received:\\n[ %s ]\\n%s' % (msg['Type'], msg['Text']), msg['FromUserName'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 虚拟员工: 语音指令交互（Conversational automation using speech/voice command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "\n",
    "@itchat.msg_register([RECORDING], isGroupChat=True)\n",
    "@itchat.msg_register([RECORDING])\n",
    "def download_files(msg):\n",
    "    msg.download(msg.fileName)\n",
    "    print('\\nDownloaded audio file name is: %s' % msg['FileName'])\n",
    "    \n",
    "    \n",
    "    ###########################################################################################################\n",
    "    #                                  call audio analysis Local AI Sphinx                                    #\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    audio_analysis_reply = u'[ Audio Analysis 音频处理结果 ]\\n'\n",
    "\n",
    "    # Voice to Text:\n",
    "    audio_analysis_reply += u'\\n[ Voice -> Text 语音识别 ]\\n'\n",
    "    response = didi_speech2text_local(didi_mp3_audio_conversion(msg['FileName']), 'en-US')\n",
    "    \n",
    "    rpa_bot_file = didi_retrieve_rpa_bot_file_fuzzy_match(response, parm_voice_command_confidence_threshold)\n",
    "    \n",
    "    if rpa_bot_file == None: # input command / rpa_bot_file NOT FOUND!\n",
    "        print(u'[ Terminal Info ] Not Confident IPA Command\\n') \n",
    "        audio_analysis_reply += str(response) + u'\\n( Not Confident IPA Command )\\n'\n",
    "    else:\n",
    "        print(u'[ Terminal Info ] RPA-Bot [ W I P ] Command : %s' % (response))\n",
    "        print(u'[ Terminal Info ] RPA-Bot [ W I P ] File    : %s' % (rpa_bot_file))\n",
    "            \n",
    "        if parm_asynchronous_process: # Don't wait for RPA-Bot completion \n",
    "            # Send 'work in progress' message triggering RPA-Bot\n",
    "            audio_analysis_reply += (u'[ Async WIP ] IPA Command triggered\\n')\n",
    "                \n",
    "            # Trigger RPA-Bot [ Asynchronous ]\n",
    "            didi_invoke_rpa_bot_async(rpa_bot_file) # No return of return_code, time_spent\n",
    "        else: # Wait for RPA-Bot completion \n",
    "            # Send 'work in progress' message triggering RPA-Bot\n",
    "            audio_analysis_reply += (u'[ Sync WIP ] IPA Command triggered\\n')\n",
    "                \n",
    "            # Trigger RPA-Bot [ Synchronously ]\n",
    "            return_code, time_spent = didi_invoke_rpa_bot(rpa_bot_file)\n",
    "            print(u'[ Terminal Info ] didi_invoke_rpa_bot(rpa_bot_file) [ Return Code : %s ]' % (return_code))\n",
    "                \n",
    "            if return_code == 0:\n",
    "                # Send confirmation message upon RPA-Bot completion\n",
    "                audio_analysis_reply += (u'[ Sync OK] [ Return Code : %s ] IPA Command completed !\\n[ Time Spent : %s seconds ]' % (return_code, time_spent))\n",
    "            else:\n",
    "                # Error when running RPA-Bot task\n",
    "                audio_analysis_reply += (u'[ Sync ERROR] [ Return Code : %s ] IPA Command failed !\\n[ Time Spent : %s seconds ]' % (return_code, time_spent))\n",
    "    \n",
    "    return audio_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interupt kernel, then logout\n",
    "# itchat.logout() # 安全退出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恭喜您！已经完成了："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第六课：交互式虚拟助手的智能应用\n",
    "### Lesson 6: Interactive Conversatioinal Virtual Assistant Applications / Intelligent Process Automations\n",
    "* 虚拟员工: 贷款填表申请审批一条龙自动化流程 （Virtual Worker: When Chat-bot meets RPA-bot for mortgage loan application automation) \n",
    "* 虚拟员工: 文字指令交互（Conversational automation using text/message command) \n",
    "* 虚拟员工: 语音指令交互（Conversational automation using speech/voice command) \n",
    "* 虚拟员工: 多种语言交互（Conversational automation with multiple languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../reference/WeChat_SamGu_QR.png' width=80% style=\"float: left;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise / Workshop Enhancement</span> Use Cloud AI APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Install the client library</span> for 虚拟员工: 语音指令交互（Conversational automation using speech/voice command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ Hints ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "# from google.cloud import speech\n",
    "# from google.cloud.speech import enums\n",
    "# from google.cloud.speech import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "# from google.cloud import texttospeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise / Workshop Enhancement</span> Use Cloud AI APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Install the client library</span> for 虚拟员工: 多种语言交互（Conversational automation with multiple languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ Hints ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "# from google.cloud import translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
